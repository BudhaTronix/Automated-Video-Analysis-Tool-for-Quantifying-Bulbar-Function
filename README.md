# Automated-Video-Analysis-Tool-for-Quantifying-Bulbar-Function

This project is developed to help researchers detect the frequency of tongue movement for ALS Bulbar Funtion.
Here we detect the tongue movement of users from a sample video input file. It gives out the counts and also tell if there are outliers in the counts.

## Installation

Python 3.7
OpenCv

## Usage

1. The script can be directly used by using the .ipynb file
2. The training function be used to further train the model with new tongue data 
3. There is GUI which is developed using FLASK

## Contributing

1. Fork it!
2. Create your feature branch: `git checkout -b my-new-feature`
3. Commit your changes: `git commit -am 'Add some feature'`
4. Push to the branch: `git push origin my-new-feature`
5. Submit a pull request :D

## Future Work

This project can be further extend by implemeting speed calculation. For speed calculation can be impleted if we re able to get the depth estimation from the video 
